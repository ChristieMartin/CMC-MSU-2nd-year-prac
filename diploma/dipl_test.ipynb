{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "from xml.dom.minidom import (parse, Element)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "corpus_filename = 'Tselina'\r\n",
    "#corpus_filename = 'pedagogika'\r\n",
    "#corpus_filename = 'sirija'\r\n",
    "\r\n",
    "file_ext = '.xml'\r\n",
    "doc = parse(corpus_filename + file_ext)\r\n",
    "sentences = doc.getElementsByTagName('S')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "f'Количество предложений в корпусе = {len(sentences)}'"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Количество предложений в корпусе = 189'"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "d = {}\r\n",
    "\r\n",
    "class Sentence:\r\n",
    "    def __init__(self, sent: Element):\r\n",
    "        self.id = sent.getAttribute('ID')\r\n",
    "        self.words = []\r\n",
    "        \r\n",
    "        self.parseWords(sent.getElementsByTagName('W'))\r\n",
    "        \r\n",
    "    def parseWords(self, rawWords):\r\n",
    "        \r\n",
    "        self.wordMap = {}\r\n",
    "        \r\n",
    "        for rawWord in rawWords:\r\n",
    "            \r\n",
    "            word = Word(rawWord, self.id)\r\n",
    "            \r\n",
    "            self.words.append(word)\r\n",
    "            \r\n",
    "            if word.dom == '_root':\r\n",
    "                self.rootWord = word\r\n",
    "                \r\n",
    "            if word.dom in self.wordMap.keys():\r\n",
    "                self.wordMap[word.dom].append(word)\r\n",
    "            else:\r\n",
    "                self.wordMap[word.dom] = [word]\r\n",
    "\r\n",
    "        for word in self.words:\r\n",
    "            if word.id in self.wordMap.keys():\r\n",
    "                for d in self.wordMap[word.id]:\r\n",
    "                    word.addWord(d)\r\n",
    "    def printGram(self):\r\n",
    "        self.rootWord.printGram(True) \r\n",
    "        \r\n",
    "        \r\n",
    "class Word:\r\n",
    "    def __init__(self, w: Element, sentId):\r\n",
    "        self.dom = w.getAttribute('DOM')\r\n",
    "        self.feat = w.getAttribute('FEAT')\r\n",
    "        self.id = w.getAttribute('ID')\r\n",
    "        self.lemma = w.getAttribute('LEMMA')\r\n",
    "        self.link = w.getAttribute('LINK')\r\n",
    "        \r\n",
    "        v = \" \".join(t.nodeValue for t in w.childNodes if t.nodeType == t.TEXT_NODE).lower().strip()\r\n",
    "        if len(v) != 0 and v[-1] == '.':\r\n",
    "            v = v[:-1]\r\n",
    "        if v != '':\r\n",
    "            if self.feat in d.keys():\r\n",
    "                d[self.feat].add(v)\r\n",
    "            else:\r\n",
    "                d[self.feat] = {v}\r\n",
    "        \r\n",
    "        \r\n",
    "        self.sentId = sentId\r\n",
    "        \r\n",
    "        self.connectedWords = []\r\n",
    "        \r\n",
    "    def addWord(self, w):\r\n",
    "        self.connectedWords.append(w)\r\n",
    "        \r\n",
    "    def printGram(self, checkProj):\r\n",
    "        if checkProj:\r\n",
    "            t = checkProjectivity(self, {}, 0)\r\n",
    "            if not t:\r\n",
    "                # закомментировать return, чтобы такие предложения не пропускались\r\n",
    "                #print(f'\\nNOT PROJECTIVE, {self.sentId}\\n')\r\n",
    "                return\r\n",
    "        print('F{' + f'[{self.feat}' + ']}->', end = '')\r\n",
    "        \r\n",
    "        if self.connectedWords == []:\r\n",
    "            print(f'[{self.feat}]\\n', end = '')\r\n",
    "            \r\n",
    "        else:\r\n",
    "            t = False\r\n",
    "            for w in self.connectedWords:\r\n",
    "                if not t and (int(w.id) > int(self.id)): \r\n",
    "                    print(f'[{self.feat}]', end = '')\r\n",
    "                    t = True\r\n",
    "                    \r\n",
    "                print(';D{[' + f'{w.feat}' + '], ' + f'{w.link}' + '};', end = '')\r\n",
    "            if not t:\r\n",
    "                print(f'[{self.feat}]', end = '')\r\n",
    "            for w in self.connectedWords:\r\n",
    "                print('\\nD{[' + f'{w.feat}], {w.link}' + '}->F{[' + f'{w.feat}' + ']}')\r\n",
    "                #print() # раскомментировать и закомментировать предыдущую, если не хотим печатать D(t, s) -> F(t)\r\n",
    "                w.printGram(False)\r\n",
    "                \r\n",
    "def checkProjectivity(rootWord, seenWordsIds, floor):\r\n",
    "    if floor not in seenWordsIds.keys():\r\n",
    "        seenWordsIds[floor] = []\r\n",
    "    if any(map(lambda x: int(x) > int(rootWord.id), seenWordsIds[floor])):\r\n",
    "        return False\r\n",
    "    seenWordsIds[floor].append(rootWord.id)\r\n",
    "    if rootWord.connectedWords == []:\r\n",
    "        return True\r\n",
    "    t = True\r\n",
    "    for w in rootWord.connectedWords:\r\n",
    "        t = t and checkProjectivity(w, seenWordsIds, floor + 1)\r\n",
    "        if not t:\r\n",
    "            return t\r\n",
    "    return t   \r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "def parseSentences():\r\n",
    "    for sent in sentences:\r\n",
    "        parseSentence(sent)\r\n",
    "\r\n",
    "def parseSentence(sent: Element):\r\n",
    "    sentence = Sentence(sent)\r\n",
    "    sentence.printGram()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "import sys\r\n",
    "filename = corpus_filename + '_' + 'gram.out'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# для теста\r\n",
    "# печатает грамматику одного предложения\r\n",
    "\r\n",
    "sentence_id = 119 #id предложения в корпусе <S ID = 'sentence_id'>\r\n",
    "\r\n",
    "filename = 'test/test.out'\r\n",
    "filename_sorted = 'test/test_sorted.out'\r\n",
    "\r\n",
    "orig_stdout = sys.stdout\r\n",
    "f = open(filename, 'w', encoding = 'utf-16')\r\n",
    "sys.stdout = f\r\n",
    "\r\n",
    "sentence = Sentence(sentences[sentence_id - 1])\r\n",
    "sentence.printGram()\r\n",
    "\r\n",
    "sys.stdout = orig_stdout\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "filename_sorted = 'test/test_gram_sorted.out'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "def printSortedNoDuplicatesFile(fname, fname_sorted):\r\n",
    "    lines_seen = set()\r\n",
    "    with open(fname, 'r', encoding = 'utf-16') as r:\r\n",
    "        with open(fname_sorted, 'w', encoding = 'utf-16') as f:\r\n",
    "            for line_orig in sorted(r):\r\n",
    "                if line_orig not in lines_seen:\r\n",
    "                    line = str(line_orig.strip())\r\n",
    "\r\n",
    "                    if len(line) != 0 and line[-1] == ';':\r\n",
    "                        line = line[:-1].strip()\r\n",
    "                    line = line.replace(';;', ';')\r\n",
    "                    line = line.replace('->;', '->')\r\n",
    "                    line += '\\n'  \r\n",
    "                    if line == '\\n':\r\n",
    "                        continue\r\n",
    "                    print(line, end = '', file = f)\r\n",
    "                    lines_seen.add(line_orig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "printSortedNoDuplicatesFile(filename, filename_sorted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "def printDictionary(d, fname):\r\n",
    "    with open(fname, 'w', encoding='utf-16') as f:\r\n",
    "        for key, value in d.items():\r\n",
    "            s = ' | '.join(value)\r\n",
    "            print(f'[{key}] = {s}', file = f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "printDictionary(d, f'test/test_dict.out')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "d_gram_map = {}\r\n",
    "f_gram_map = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "def addToMap(mapName, key, value):\r\n",
    "    if key in mapName.keys():\r\n",
    "        mapName[key].append(value)\r\n",
    "    else:\r\n",
    "        mapName[key] = [value]\r\n",
    "\r\n",
    "def mapGrammar(filename):\r\n",
    "    with open(filename, 'r', encoding = 'utf-16') as r:\r\n",
    "        for line in r:\r\n",
    "            s = line.split('->')\r\n",
    "            if len(s) > 1:\r\n",
    "                p = s[0].strip()\r\n",
    "                w = s[1].strip().replace('\\n', '')\r\n",
    "                if (p[0] == 'D'):\r\n",
    "                    addToMap(d_gram_map, p, w)\r\n",
    "                else:\r\n",
    "                    addToMap(f_gram_map, p, w)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "def printGrammarMap(mapName, filename_min):\r\n",
    "    with open(filename_min, 'w', encoding = 'utf-16') as f:\r\n",
    "        for key, value in mapName.items():\r\n",
    "            s = '|'.join(value)\r\n",
    "            s = ';'.join(s.split(';'))\r\n",
    "            print(key, '->', s, file = f, sep = '')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "def dMapFirstStep():\r\n",
    "    for key, value in d_gram_map.items():\r\n",
    "        d_gram_map[key] = f_gram_map[d_gram_map[key][0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "def removeRecursion(d_gram_map):\r\n",
    "    seen = []\r\n",
    "    t = True\r\n",
    "    while t:\r\n",
    "        t = False\r\n",
    "        for key, value in d_gram_map.items():\r\n",
    "            if 'D{' not in str(value) and key not in seen:\r\n",
    "                t = True\r\n",
    "                seen.append(key)\r\n",
    "                for k, v in d_gram_map.items():\r\n",
    "                    l = []\r\n",
    "                    if key in str(v):\r\n",
    "                        for item in v:\r\n",
    "                            for val in value:\r\n",
    "                                l.append(item.replace(key, val))\r\n",
    "                    if l != []:\r\n",
    "                        d_gram_map[k] = l\r\n",
    "                        \r\n",
    "    return d_gram_map\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "import copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "d_gram_map = {}\r\n",
    "f_gram_map = {}\r\n",
    "\r\n",
    "\r\n",
    "mapGrammar('test/test_sorted.out')\r\n",
    "    \r\n",
    "dMapFirstStep()\r\n",
    "\r\n",
    "new_map = removeRecursion(copy.deepcopy(d_gram_map))\r\n",
    "\r\n",
    "printGrammarMap(new_map, 'test/test_gram_min.out')\r\n",
    "printSortedNoDuplicatesFile('test/test_gram_min.out', 'test/test_gram_min_sorted.out')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test/test_sorted.out'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9380/4115384291.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmapGrammar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test/test_sorted.out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdMapFirstStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9380/3669768842.py\u001b[0m in \u001b[0;36mmapGrammar\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmapGrammar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-16'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'->'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test/test_sorted.out'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class RTNNode:\r\n",
    "    def __init__(self, s, i, isEnd = False):\r\n",
    "        self.s = s\r\n",
    "        self.i = i\r\n",
    "        self.isEnd = isEnd\r\n",
    "        self.connected = None\r\n",
    "    def connect(self, node):\r\n",
    "        self.connected = node\r\n",
    "    def printNode(self):\r\n",
    "        s = f'${self.s}' if self.s[0] == 'D' else self.s\r\n",
    "        if self.isEnd:\r\n",
    "            print(s, '*', end = '')\r\n",
    "            print(';')\r\n",
    "        else:\r\n",
    "            print(s, self.i, end = '')\r\n",
    "            print(';')\r\n",
    "            \r\n",
    "    def printNodes(self, printItself = False):\r\n",
    "        if printItself:\r\n",
    "            self.printNode()\r\n",
    "        if not self.isEnd:\r\n",
    "            print(f'{self.i}:')\r\n",
    "        if self.connected != None:\r\n",
    "            self.connected.printNodes(printItself = True)\r\n",
    "        \r\n",
    "\r\n",
    "def toRTN(new_map, fname):\r\n",
    "    orig_stdout = sys.stdout\r\n",
    "    f = open(fname, 'w', encoding = 'utf-16')\r\n",
    "    sys.stdout = f\r\n",
    "    for key in new_map.keys():\r\n",
    "        l = new_map[key]\r\n",
    "        new_l = []\r\n",
    "        m_len = 0\r\n",
    "        for item in l:\r\n",
    "            p = item.split(';')\r\n",
    "            if len(p) > m_len:\r\n",
    "                m_len = len(p)\r\n",
    "            new_l.append(p)\r\n",
    "        print(f'${key}')\r\n",
    "        print('(')\r\n",
    "        j = 0\r\n",
    "        k = 0\r\n",
    "        t = 0\r\n",
    "        m = {}\r\n",
    "        last_ones = []\r\n",
    "        for items in new_l:\r\n",
    "            last = None\r\n",
    "            if k == 0:\r\n",
    "                k = len(items) - 1\r\n",
    "            else:\r\n",
    "                k += t\r\n",
    "            j = k\r\n",
    "            t = 0\r\n",
    "            \r\n",
    "            for i, item in enumerate(reversed(items)):\r\n",
    "                if i == 0:\r\n",
    "                    r = RTNNode(item, 0, isEnd = i == 0)\r\n",
    "                    last = r\r\n",
    "                    continue\r\n",
    "                r = RTNNode(item, j, isEnd = i == 0)\r\n",
    "                j -= 1\r\n",
    "                t += 1\r\n",
    "            \r\n",
    "                if last != None:\r\n",
    "                    r.connect(last)\r\n",
    "                last = r\r\n",
    "                \r\n",
    "            last_ones.append(last)\r\n",
    "                \r\n",
    "        print('0:')\r\n",
    "        for i in last_ones:\r\n",
    "            i.printNode()\r\n",
    "        for i in last_ones:\r\n",
    "            i.printNodes()        \r\n",
    "        print(')')\r\n",
    "        print()\r\n",
    "    sys.stdout = orig_stdout\r\n",
    "    f.close()            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_new_map = {\r\n",
    "    'S': ['D1;D2;D3;t;D4;D5'],\r\n",
    "    'S1': ['a;D1', 'D2;D1']\r\n",
    "}\r\n",
    "\r\n",
    "t_new_map = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if t_new_map:\r\n",
    "    toRTN(test_new_map, f't_new_map.out')\r\n",
    "else:\r\n",
    "    toRTN(new_map, f'test/test_rtn.out')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  },
  "interpreter": {
   "hash": "b4965ae4014b87d6ab865b0dc5968b1df31c5fe8fcdbcfb3aced629f423627f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}