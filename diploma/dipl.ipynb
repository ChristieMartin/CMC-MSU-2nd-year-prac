{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "from xml.dom.minidom import (parse, Element)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "corpus_filename = 'Tselina'\r\n",
    "#corpus_filename = 'pedagogika'\r\n",
    "#corpus_filename = 'sirija'\r\n",
    "\r\n",
    "file_ext = '.xml'\r\n",
    "doc = parse(corpus_filename + file_ext)\r\n",
    "sentences = doc.getElementsByTagName('S') # все элементы с тегом S (все предложения корпуса)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "f'Количество предложений в корпусе = {len(sentences)}'"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Количество предложений в корпусе = 189'"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "d = {} # словарь всей грамматики граммема - слова\r\n",
    "\r\n",
    "class Sentence:\r\n",
    "    def __init__(self, sent: Element):\r\n",
    "        self.id = sent.getAttribute('ID')\r\n",
    "        self.words = []\r\n",
    "        \r\n",
    "        self.parseWords(sent.getElementsByTagName('W'))\r\n",
    "        # получаем все элементы xml с тегом W (слова)\r\n",
    "        \r\n",
    "    def parseWords(self, rawWords):\r\n",
    "        \r\n",
    "        self.wordMap = {} # для последующего связывания слов\r\n",
    "        # ключ - доминатор(айди доминатора) этого слова\r\n",
    "        # значение - список слов, для которых доминатор равен ключу\r\n",
    "        \r\n",
    "        for rawWord in rawWords:\r\n",
    "            \r\n",
    "            word = Word(rawWord, self.id) # переносим в класс\r\n",
    "            \r\n",
    "            self.words.append(word) # добавляем в общий список слов\r\n",
    "            \r\n",
    "            if word.dom == '_root':\r\n",
    "                self.rootWord = word # корневое слово\r\n",
    "                \r\n",
    "            # добавление в мапу\r\n",
    "            if word.dom in self.wordMap.keys():\r\n",
    "                self.wordMap[word.dom].append(word)\r\n",
    "            else:\r\n",
    "                self.wordMap[word.dom] = [word]\r\n",
    "\r\n",
    "        # цикл по всем словам, чтобы связать их с помощью мапы\r\n",
    "        for word in self.words:\r\n",
    "            if word.id in self.wordMap.keys():\r\n",
    "                for d in self.wordMap[word.id]:\r\n",
    "                    word.addWord(d)\r\n",
    "    def printGram(self):\r\n",
    "        # печать грамматики предложения = печать грамматики одного слова(которое печатает все свои связанные слова, то есть все слова в предложении)\r\n",
    "        self.rootWord.printGram(True) \r\n",
    "        \r\n",
    "        \r\n",
    "class Word:\r\n",
    "    def __init__(self, w: Element, sentId):\r\n",
    "        self.dom = w.getAttribute('DOM')\r\n",
    "        self.feat = w.getAttribute('FEAT')\r\n",
    "        self.id = w.getAttribute('ID')\r\n",
    "        self.lemma = w.getAttribute('LEMMA')\r\n",
    "        self.link = w.getAttribute('LINK')\r\n",
    "        \r\n",
    "        v = \" \".join(t.nodeValue for t in w.childNodes if t.nodeType == t.TEXT_NODE).lower().strip()\r\n",
    "        # v - просто слово\r\n",
    "        \r\n",
    "        if len(v) != 0 and v[-1] == '.':\r\n",
    "            v = v[:-1]\r\n",
    "        if v != '':\r\n",
    "            # добавление слова в словарь\r\n",
    "            if self.feat in d.keys():\r\n",
    "                d[self.feat].add(v)\r\n",
    "            else:\r\n",
    "                d[self.feat] = {v}\r\n",
    "        \r\n",
    "        \r\n",
    "        self.sentId = sentId\r\n",
    "        \r\n",
    "        self.connectedWords = [] #связанные с этим словом слова\r\n",
    "        \r\n",
    "    def addWord(self, w):\r\n",
    "        # добавление слова в связанные с этим словом слова\r\n",
    "        self.connectedWords.append(w)\r\n",
    "        \r\n",
    "    def printGram(self, checkProj):\r\n",
    "        if checkProj:\r\n",
    "            t = checkProjectivity(self, {}, 0)\r\n",
    "            if not t:\r\n",
    "                # закомментировать return, чтобы такие предложения не пропускались\r\n",
    "                #print(f'\\nNOT PROJECTIVE, {self.sentId}\\n')\r\n",
    "                return\r\n",
    "        print('F{' + f'[{self.feat}' + ']}->', end = '') # F(t) ->\r\n",
    "        \r\n",
    "        if self.connectedWords == []:\r\n",
    "            print(f'[{self.feat}]\\n', end = '') # когда узел - терминальный\r\n",
    "            \r\n",
    "        else:\r\n",
    "            t = False # для расположения граммем слова в нужном месте\r\n",
    "            for w in self.connectedWords:\r\n",
    "                \r\n",
    "                # проход по всем словам в связанных словах\r\n",
    "                if not t and (int(w.id) > int(self.id)): \r\n",
    "                    # когда этого не происходило ранее и когда айди текущего связанного слова превысило айди самого слова\r\n",
    "                    print(f'[{self.feat}]', end = '')\r\n",
    "                    t = True\r\n",
    "                    \r\n",
    "                print(';D{[' + f'{w.feat}' + '], ' + f'{w.link}' + '};', end = '') # D(t, s)\r\n",
    "            if not t:\r\n",
    "                print(f'[{self.feat}]', end = '')\r\n",
    "            for w in self.connectedWords:\r\n",
    "                print('\\nD{[' + f'{w.feat}], {w.link}' + '}->F{[' + f'{w.feat}' + ']}') #D(t, s) -> F(t)\r\n",
    "                #print() # раскомментировать и закомментировать предыдущую, если не хотим печатать D(t, s) -> F(t)\r\n",
    "                w.printGram(False)\r\n",
    "                \r\n",
    "def checkProjectivity(rootWord, seenWordsIds, floor):\r\n",
    "    if floor not in seenWordsIds.keys():\r\n",
    "        # создаем список для этого яруса\r\n",
    "        seenWordsIds[floor] = []\r\n",
    "    if any(map(lambda x: int(x) > int(rootWord.id), seenWordsIds[floor])):\r\n",
    "        # если в истории этого яруса есть id больший, чем id текущего узла\r\n",
    "        return False\r\n",
    "    seenWordsIds[floor].append(rootWord.id) # добавляем в историю id текущего узла\r\n",
    "    if rootWord.connectedWords == []: # если нет поддеревьев\r\n",
    "        return True\r\n",
    "    t = True\r\n",
    "    for w in rootWord.connectedWords:\r\n",
    "        # проверяем все поддеревья\r\n",
    "        t = t and checkProjectivity(w, seenWordsIds, floor + 1)\r\n",
    "        if not t:\r\n",
    "            # если случай найден, то возвращаем сразу же\r\n",
    "            return t\r\n",
    "    return t   \r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "def parseSentences():\r\n",
    "    for sent in sentences:\r\n",
    "        # пробегаемся по всем предложениям корпуса\r\n",
    "        parseSentence(sent)\r\n",
    "\r\n",
    "def parseSentence(sent: Element):\r\n",
    "    sentence = Sentence(sent)\r\n",
    "    sentence.printGram()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import sys\r\n",
    "filename = corpus_filename + '_' + 'gram.out'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "orig_stdout = sys.stdout\r\n",
    "f = open(filename, 'w', encoding = 'utf-8')\r\n",
    "sys.stdout = f\r\n",
    "# перенаправление stdout в файл, чтобы все печаталось в файл\r\n",
    "\r\n",
    "parseSentences()\r\n",
    "\r\n",
    "# перенаправление обратно\r\n",
    "sys.stdout = orig_stdout\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "filename_sorted = corpus_filename + '_' + 'gram_sorted.out'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# сортировка и удаление дубликатов в файле\r\n",
    "def printSortedNoDuplicatesFile(fname, fname_sorted):\r\n",
    "    lines_seen = set()\r\n",
    "    with open(fname, 'r', encoding = 'utf-8') as r:\r\n",
    "        with open(fname_sorted, 'w', encoding = 'utf-8') as f:\r\n",
    "            for line_orig in sorted(r):\r\n",
    "                if line_orig not in lines_seen:\r\n",
    "                    # чистим от пробелов\r\n",
    "                    line = str(line_orig.strip())\r\n",
    "\r\n",
    "                    if len(line) != 0 and line[-1] == ';':\r\n",
    "                        # удаляю лишние ;\r\n",
    "                        line = line[:-1].strip()\r\n",
    "                        \r\n",
    "                    line = line.replace(';;', ';')\r\n",
    "                    line = line.replace('->;', '->')\r\n",
    "                    \r\n",
    "                    line += '\\n'  \r\n",
    "                    if line == '\\n':\r\n",
    "                        # empty line\r\n",
    "                        continue\r\n",
    "                    \r\n",
    "                    print(line, end = '', file = f)\r\n",
    "                    \r\n",
    "                    lines_seen.add(line_orig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "printSortedNoDuplicatesFile(filename, filename_sorted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# печать словаря\r\n",
    "def printDictionary(d, fname):\r\n",
    "    with open(fname, 'w', encoding='utf-8') as f:\r\n",
    "        for key, value in d.items():\r\n",
    "            s = ' | '.join(value)\r\n",
    "            print(f'[{key}] = {s}', file = f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "printDictionary(d, f'{corpus_filename}_dict.out')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "d_gram_map = {}\r\n",
    "f_gram_map = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "def addToMap(mapName, key, value):\r\n",
    "    # добавление в словарь по ключу key value (само значение - список)\r\n",
    "    if key in mapName.keys():\r\n",
    "        mapName[key].append(value)\r\n",
    "    else:\r\n",
    "        mapName[key] = [value]\r\n",
    "\r\n",
    "def mapGrammar(filename):\r\n",
    "    # запись всей грамматики в словарь\r\n",
    "    # d_gram_map - словарь для D нетерминалов\r\n",
    "    # f_gram_map - словарь для F нетерминалов\r\n",
    "    \r\n",
    "    with open(filename, 'r', encoding = 'utf-8') as r:\r\n",
    "        for line in r:\r\n",
    "            s = line.split('->')\r\n",
    "            p = s[0].strip()\r\n",
    "            w = s[1].strip().replace('\\n', '')\r\n",
    "            if (p[0] == 'D'):\r\n",
    "                addToMap(d_gram_map, p, w)\r\n",
    "            else:\r\n",
    "                addToMap(f_gram_map, p, w)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "def printGrammarMap(mapName, filename_min):\r\n",
    "    # печать грамматики\r\n",
    "    with open(filename_min, 'w', encoding = 'utf-8') as f:\r\n",
    "        for key, value in mapName.items():\r\n",
    "            s = '|'.join(value)\r\n",
    "            s = ';'.join(s.split(';'))\r\n",
    "            print(key, '->', s, file = f, sep = '')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "def setFToD():\r\n",
    "    # подстановка F нетерминалов в D\r\n",
    "    for key, value in d_gram_map.items():\r\n",
    "        d_gram_map[key] = f_gram_map[d_gram_map[key][0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "def removeRecursion(d_gram_map):\r\n",
    "    # подставить D в D где это возможно\r\n",
    "    seen = []\r\n",
    "    t = True\r\n",
    "    while t: \r\n",
    "        t = False # закончится, если справа не останется D, или все правила просмотрены и обработаны(останутся только те, в которых есть рекурсии)\r\n",
    "        for key, value in d_gram_map.items():\r\n",
    "            if 'D{' not in str(value) and key not in seen: # если справа есть нетерминал D\r\n",
    "                t = True\r\n",
    "                seen.append(key)\r\n",
    "                \r\n",
    "                for k, v in d_gram_map.items():\r\n",
    "                    l = []\r\n",
    "                    if key in str(v):\r\n",
    "                        for item in v:\r\n",
    "                            for val in value:\r\n",
    "                                l.append(item.replace(key, val)) # заменяю D на D из других правил\r\n",
    "                    if l != []:\r\n",
    "                        d_gram_map[k] = l\r\n",
    "                        \r\n",
    "    return d_gram_map\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "d_gram_map = {}\r\n",
    "f_gram_map = {}\r\n",
    "\r\n",
    "\r\n",
    "mapGrammar(f'{corpus_filename}_gram_sorted.out')\r\n",
    "    \r\n",
    "setFToD()\r\n",
    "\r\n",
    "new_map = removeRecursion(copy.deepcopy(d_gram_map))\r\n",
    "printGrammarMap(new_map, f'{corpus_filename}_gram_min.out')\r\n",
    "printSortedNoDuplicatesFile(f'{corpus_filename}_gram_min.out', f'{corpus_filename}_gram_min_sorted.out')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class RTNNode:\r\n",
    "    # класс для рекурсивной сети переходов\r\n",
    "    # s - терминал или нетерминал\r\n",
    "    # i - в какое состояние переходим по этому нетерминалу/терминалу(цифра после)\r\n",
    "    # isEnd - последнее ли правило в альтернативе\r\n",
    "    # connected - с каким RTNNode связано текущее\r\n",
    "    def __init__(self, s, i, isEnd = False):\r\n",
    "        self.s = s\r\n",
    "        self.i = i\r\n",
    "        self.isEnd = isEnd\r\n",
    "        self.connected = None\r\n",
    "        \r\n",
    "    # связать с другим RTNNode\r\n",
    "    def connect(self, node):\r\n",
    "        self.connected = node\r\n",
    "        \r\n",
    "    # печать одного RTNNode\r\n",
    "    def printNode(self):\r\n",
    "        \r\n",
    "        s = f'${self.s}' if self.s[0] == 'D' else self.s\r\n",
    "        \r\n",
    "        if self.isEnd:\r\n",
    "            print(s, '*', end = '')\r\n",
    "            print(';')\r\n",
    "        else:\r\n",
    "            print(s, self.i, end = '')\r\n",
    "            print(';')\r\n",
    "           \r\n",
    "    # печать RTNNode если printItself True, иначе напечатать все связанные с этим RTNNode \r\n",
    "    def printNodes(self, printItself = False):\r\n",
    "        if printItself:\r\n",
    "            self.printNode()\r\n",
    "        if not self.isEnd:\r\n",
    "            print(f'{self.i}:')\r\n",
    "        if self.connected != None:\r\n",
    "            self.connected.printNodes(printItself = True)\r\n",
    "        \r\n",
    "\r\n",
    "def toRTN(new_map, fname):\r\n",
    "    \r\n",
    "    orig_stdout = sys.stdout\r\n",
    "    f = open(fname, 'w', encoding = 'utf-8')\r\n",
    "    sys.stdout = f\r\n",
    "    \r\n",
    "    for key in new_map.keys():\r\n",
    "        l = new_map[key] # ['a;D1', 'D2;D1']\r\n",
    "        new_l = [] # [['a', 'D1'], ['D2', 'D1']]\r\n",
    "        for item in l:\r\n",
    "            p = item.split(';')\r\n",
    "            new_l.append(p)\r\n",
    "            \r\n",
    "        print(f'${key}')\r\n",
    "        print('(')\r\n",
    "        \r\n",
    "        j = 0\r\n",
    "        k = 0\r\n",
    "        t = 0\r\n",
    "        m = {}\r\n",
    "        \r\n",
    "        start_ones = []\r\n",
    "        \r\n",
    "        for items in new_l:\r\n",
    "            \r\n",
    "            last = None # RTNNode на предыдущей итерации\r\n",
    "            \r\n",
    "            if k == 0:\r\n",
    "                k = len(items) - 1 # для самого первого ставим длину всего списка\r\n",
    "            else:\r\n",
    "                k += t # иначе добавляем t\r\n",
    "                \r\n",
    "            j = k # индекс по которому будем переходить\r\n",
    "            t = 0\r\n",
    "            \r\n",
    "            for i, item in enumerate(reversed(items)):\r\n",
    "                # цикл по всем терминалам и нетерминалам в альтернативе в обратном порядке, чтобы успешно связать индекс состояния \r\n",
    "                if i == 0:\r\n",
    "                    r = RTNNode(item, 0, isEnd = True)\r\n",
    "                    last = r \r\n",
    "                    continue\r\n",
    "                \r\n",
    "                r = RTNNode(item, j)\r\n",
    "                \r\n",
    "                j -= 1 # уменьшаем j\r\n",
    "                t += 1 # инкрементируем t\r\n",
    "            \r\n",
    "                if last != None:\r\n",
    "                    r.connect(last) # связываем текущий с предыдущей итерацией\r\n",
    "                    \r\n",
    "                last = r\r\n",
    "                \r\n",
    "            start_ones.append(last)\r\n",
    "        \r\n",
    "        # печать всего RTNNode\r\n",
    "        print('0:')\r\n",
    "        # печать 0 состояния\r\n",
    "        for i in start_ones:\r\n",
    "            i.printNode()\r\n",
    "        # печать всех остальных\r\n",
    "        for i in start_ones:\r\n",
    "            i.printNodes()  \r\n",
    "                  \r\n",
    "        print(')')\r\n",
    "        print()\r\n",
    "        \r\n",
    "    sys.stdout = orig_stdout\r\n",
    "    f.close()\r\n",
    "                        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "toRTN(new_map, f'{corpus_filename}_rtn.out')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  },
  "interpreter": {
   "hash": "b4965ae4014b87d6ab865b0dc5968b1df31c5fe8fcdbcfb3aced629f423627f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}