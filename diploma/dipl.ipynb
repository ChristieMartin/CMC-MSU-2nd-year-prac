{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import (parse, Element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filename = 'Tselina'\n",
    "#corpus_filename = 'pedagogika'\n",
    "#corpus_filename = 'sirija'\n",
    "\n",
    "file_ext = '.xml'\n",
    "doc = parse(corpus_filename + file_ext)\n",
    "sentences = doc.getElementsByTagName('S') # все элементы с тегом S (все предложения корпуса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество предложений в корпусе = 189'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Количество предложений в корпусе = {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {} # словарь всей грамматики граммема - слова\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, sent: Element):\n",
    "        self.id = sent.getAttribute('ID')\n",
    "        self.words = []\n",
    "        \n",
    "        self.parseWords(sent.getElementsByTagName('W'))\n",
    "        # получаем все элементы xml с тегом W (слова)\n",
    "        \n",
    "    def parseWords(self, rawWords):\n",
    "        \n",
    "        self.wordMap = {} # для последующего связывания слов\n",
    "        # ключ - доминатор(айди доминатора) этого слова\n",
    "        # значение - список слов, для которых доминатор равен ключу\n",
    "        \n",
    "        for rawWord in rawWords:\n",
    "            \n",
    "            word = Word(rawWord, self.id) # переносим в класс\n",
    "            \n",
    "            self.words.append(word) # добавляем в общий список слов\n",
    "            \n",
    "            if word.dom == '_root':\n",
    "                self.rootWord = word # корневое слово\n",
    "                \n",
    "            # добавление в мапу\n",
    "            if word.dom in self.wordMap.keys():\n",
    "                self.wordMap[word.dom].append(word)\n",
    "            else:\n",
    "                self.wordMap[word.dom] = [word]\n",
    "\n",
    "        # цикл по всем словам, чтобы связать их с помощью мапы\n",
    "        for word in self.words:\n",
    "            if word.id in self.wordMap.keys():\n",
    "                for d in self.wordMap[word.id]:\n",
    "                    word.addWord(d)\n",
    "    def printGram(self):\n",
    "        # печать грамматики предложения = печать грамматики одного слова(которое печатает все свои связанные слова, то есть все слова в предложении)\n",
    "        self.rootWord.printGram(True) \n",
    "        \n",
    "        \n",
    "class Word:\n",
    "    def __init__(self, w: Element, sentId):\n",
    "        self.dom = w.getAttribute('DOM')\n",
    "        self.feat = w.getAttribute('FEAT')\n",
    "        self.id = w.getAttribute('ID')\n",
    "        self.lemma = w.getAttribute('LEMMA')\n",
    "        self.link = w.getAttribute('LINK')\n",
    "        \n",
    "        v = \" \".join(t.nodeValue for t in w.childNodes if t.nodeType == t.TEXT_NODE).lower().strip()\n",
    "        # v - просто слово\n",
    "        \n",
    "        if len(v) != 0 and v[-1] == '.':\n",
    "            v = v[:-1]\n",
    "        if v != '':\n",
    "            # добавление слова в словарь\n",
    "            if self.feat in d.keys():\n",
    "                d[self.feat].add(v)\n",
    "            else:\n",
    "                d[self.feat] = {v}\n",
    "        \n",
    "        \n",
    "        self.sentId = sentId\n",
    "        \n",
    "        self.connectedWords = [] #связанные с этим словом слова\n",
    "        \n",
    "    def addWord(self, w):\n",
    "        # добавление слова в связанные с этим словом слова\n",
    "        self.connectedWords.append(w)\n",
    "        \n",
    "    def printGram(self, checkProj):\n",
    "        if checkProj:\n",
    "            t = checkProjectivity(self, {}, 0)\n",
    "            if not t:\n",
    "                # закомментировать return, чтобы такие предложения не пропускались\n",
    "                #print(f'\\nNOT PROJECTIVE, {self.sentId}\\n')\n",
    "                return\n",
    "        print('F{' + f'[{self.feat}' + ']}->', end = '') # F(t) ->\n",
    "        \n",
    "        if self.connectedWords == []:\n",
    "            print(f'[{self.feat}]\\n', end = '') # когда узел - терминальный\n",
    "            \n",
    "        else:\n",
    "            t = False # для расположения граммем слова в нужном месте\n",
    "            for w in self.connectedWords:\n",
    "                \n",
    "                # проход по всем словам в связанных словах\n",
    "                if not t and (int(w.id) > int(self.id)): \n",
    "                    # когда этого не происходило ранее и когда айди текущего связанного слова превысило айди самого слова\n",
    "                    print(f'[{self.feat}]', end = '')\n",
    "                    t = True\n",
    "                    \n",
    "                print(';D{[' + f'{w.feat}' + '], ' + f'{w.link}' + '};', end = '') # D(t, s)\n",
    "            if not t:\n",
    "                print(f'[{self.feat}]', end = '')\n",
    "            for w in self.connectedWords:\n",
    "                print('\\nD{[' + f'{w.feat}], {w.link}' + '}->F{[' + f'{w.feat}' + ']}') #D(t, s) -> F(t)\n",
    "                #print() # раскомментировать и закомментировать предыдущую, если не хотим печатать D(t, s) -> F(t)\n",
    "                w.printGram(False)\n",
    "                \n",
    "def checkProjectivity(rootWord, seenWordsIds, floor):\n",
    "    if floor not in seenWordsIds.keys():\n",
    "        # создаем список для этого яруса\n",
    "        seenWordsIds[floor] = []\n",
    "    if any(map(lambda x: int(x) > int(rootWord.id), seenWordsIds[floor])):\n",
    "        # если в истории этого яруса есть id больший, чем id текущего узла\n",
    "        return False\n",
    "    seenWordsIds[floor].append(rootWord.id) # добавляем в историю id текущего узла\n",
    "    if rootWord.connectedWords == []: # если нет поддеревьев\n",
    "        return True\n",
    "    t = True\n",
    "    for w in rootWord.connectedWords:\n",
    "        # проверяем все поддеревья\n",
    "        t = t and checkProjectivity(w, seenWordsIds, floor + 1)\n",
    "        if not t:\n",
    "            # если случай найден, то возвращаем сразу же\n",
    "            return t\n",
    "    return t   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentences():\n",
    "    for sent in sentences:\n",
    "        # пробегаемся по всем предложениям корпуса\n",
    "        parseSentence(sent)\n",
    "\n",
    "def parseSentence(sent: Element):\n",
    "    sentence = Sentence(sent)\n",
    "    sentence.printGram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "filename = corpus_filename + '_' + 'gram.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_stdout = sys.stdout\n",
    "f = open(filename, 'w', encoding = 'utf-16')\n",
    "sys.stdout = f\n",
    "# перенаправление stdout в файл, чтобы все печаталось в файл\n",
    "\n",
    "parseSentences()\n",
    "\n",
    "# перенаправление обратно\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_sorted = corpus_filename + '_' + 'gram_sorted.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сортировка и удаление дубликатов в файле\n",
    "def printSortedNoDuplicatesFile(fname, fname_sorted):\n",
    "    lines_seen = set()\n",
    "    with open(fname, 'r', encoding = 'utf-16') as r:\n",
    "        with open(fname_sorted, 'w', encoding = 'utf-16') as f:\n",
    "            for line_orig in sorted(r):\n",
    "                if line_orig not in lines_seen:\n",
    "                    # чистим от пробелов\n",
    "                    line = str(line_orig.strip())\n",
    "\n",
    "                    if len(line) != 0 and line[-1] == ';':\n",
    "                        # удаляю лишние ;\n",
    "                        line = line[:-1].strip()\n",
    "                        \n",
    "                    line = line.replace(';;', ';')\n",
    "                    line = line.replace('->;', '->')\n",
    "                    \n",
    "                    line += '\\n'  \n",
    "                    if line == '\\n':\n",
    "                        # empty line\n",
    "                        continue\n",
    "                    \n",
    "                    print(line, end = '', file = f)\n",
    "                    \n",
    "                    lines_seen.add(line_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "printSortedNoDuplicatesFile(filename, filename_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# печать словаря\n",
    "def printDictionary(d, fname):\n",
    "    with open(fname, 'w', encoding='utf-16') as f:\n",
    "        for key, value in d.items():\n",
    "            s = ' | '.join(value)\n",
    "            print(f'[{key}] = {s}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "printDictionary(d, f'{corpus_filename}_dict.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gram_map = {}\n",
    "f_gram_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToMap(mapName, key, value):\n",
    "    # добавление в словарь по ключу key value (само значение - список)\n",
    "    if key in mapName.keys():\n",
    "        mapName[key].append(value)\n",
    "    else:\n",
    "        mapName[key] = [value]\n",
    "\n",
    "def mapGrammar(filename):\n",
    "    # запись всей грамматики в словарь\n",
    "    # d_gram_map - словарь для D нетерминалов\n",
    "    # f_gram_map - словарь для F нетерминалов\n",
    "    \n",
    "    with open(filename, 'r', encoding = 'utf-16') as r:\n",
    "        for line in r:\n",
    "            s = line.split('->')\n",
    "            p = s[0].strip()\n",
    "            w = s[1].strip().replace('\\n', '')\n",
    "            if (p[0] == 'D'):\n",
    "                addToMap(d_gram_map, p, w)\n",
    "            else:\n",
    "                addToMap(f_gram_map, p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGrammarMap(mapName, filename_min):\n",
    "    # печать грамматики\n",
    "    with open(filename_min, 'w', encoding = 'utf-16') as f:\n",
    "        for key, value in mapName.items():\n",
    "            s = '|'.join(value)\n",
    "            s = ';'.join(s.split(';'))\n",
    "            print(key, '->', s, file = f, sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setFToD():\n",
    "    # подстановка F нетерминалов в D\n",
    "    for key, value in d_gram_map.items():\n",
    "        d_gram_map[key] = f_gram_map[d_gram_map[key][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeRecursion(d_gram_map):\n",
    "    # подставить D в D где это возможно\n",
    "    seen = []\n",
    "    t = True\n",
    "    while t: \n",
    "        t = False # закончится, если справа не останется D, или все правила просмотрены и обработаны(останутся только те, в которых есть рекурсии)\n",
    "        for key, value in d_gram_map.items():\n",
    "            if 'D{' not in str(value) and key not in seen: # если справа есть нетерминал D\n",
    "                t = True\n",
    "                seen.append(key)\n",
    "                \n",
    "                for k, v in d_gram_map.items():\n",
    "                    l = []\n",
    "                    if key in str(v):\n",
    "                        for item in v:\n",
    "                            for val in value:\n",
    "                                l.append(item.replace(key, val)) # заменяю D на D из других правил\n",
    "                    if l != []:\n",
    "                        d_gram_map[k] = l\n",
    "                        \n",
    "    return d_gram_map\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gram_map = {}\n",
    "f_gram_map = {}\n",
    "\n",
    "\n",
    "mapGrammar(f'{corpus_filename}_gram_sorted.out')\n",
    "    \n",
    "setFToD()\n",
    "\n",
    "new_map = removeRecursion(copy.deepcopy(d_gram_map))\n",
    "printGrammarMap(new_map, f'{corpus_filename}_gram_min.out')\n",
    "printSortedNoDuplicatesFile(f'{corpus_filename}_gram_min.out', f'{corpus_filename}_gram_min_sorted.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTNNode:\n",
    "    # класс для рекурсивной сети переходов\n",
    "    # s - терминал или нетерминал\n",
    "    # i - в какое состояние переходим по этому нетерминалу/терминалу(цифра после)\n",
    "    # isEnd - последнее ли правило в альтернативе\n",
    "    # connected - с каким RTNNode связано текущее\n",
    "    def __init__(self, s, i, isEnd = False):\n",
    "        self.s = s\n",
    "        self.i = i\n",
    "        self.isEnd = isEnd\n",
    "        self.connected = None\n",
    "        \n",
    "    # связать с другим RTNNode\n",
    "    def connect(self, node):\n",
    "        self.connected = node\n",
    "        \n",
    "    # печать одного RTNNode\n",
    "    def printNode(self):\n",
    "        \n",
    "        s = f'${self.s}' if self.s[0] == 'D' else self.s\n",
    "        \n",
    "        if self.isEnd:\n",
    "            print(s, '*', end = '')\n",
    "            print(';')\n",
    "        else:\n",
    "            print(s, self.i, end = '')\n",
    "            print(';')\n",
    "           \n",
    "    # печать RTNNode если printItself True, иначе напечатать все связанные с этим RTNNode \n",
    "    def printNodes(self, printItself = False):\n",
    "        if printItself:\n",
    "            self.printNode()\n",
    "        if not self.isEnd:\n",
    "            print(f'{self.i}:')\n",
    "        if self.connected != None:\n",
    "            self.connected.printNodes(printItself = True)\n",
    "        \n",
    "\n",
    "def toRTN(new_map, fname):\n",
    "    \n",
    "    orig_stdout = sys.stdout\n",
    "    f = open(fname, 'w', encoding = 'utf-16')\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for key in new_map.keys():\n",
    "        l = new_map[key] # ['a;D1', 'D2;D1']\n",
    "        new_l = [] # [['a', 'D1'], ['D2', 'D1']]\n",
    "        for item in l:\n",
    "            p = item.split(';')\n",
    "            new_l.append(p)\n",
    "            \n",
    "        print(f'${key}')\n",
    "        print('(')\n",
    "        \n",
    "        j = 0\n",
    "        k = 0\n",
    "        t = 0\n",
    "        m = {}\n",
    "        \n",
    "        start_ones = []\n",
    "        \n",
    "        for items in new_l:\n",
    "            \n",
    "            last = None # RTNNode на предыдущей итерации\n",
    "            \n",
    "            if k == 0:\n",
    "                k = len(items) - 1 # для самого первого ставим длину всего списка\n",
    "            else:\n",
    "                k += t # иначе добавляем t\n",
    "                \n",
    "            j = k # индекс по которому будем переходить\n",
    "            t = 0\n",
    "            \n",
    "            for i, item in enumerate(reversed(items)):\n",
    "                # цикл по всем терминалам и нетерминалам в альтернативе в обратном порядке, чтобы успешно связать индекс состояния \n",
    "                if i == 0:\n",
    "                    r = RTNNode(item, 0, isEnd = True)\n",
    "                    last = r \n",
    "                    continue\n",
    "                \n",
    "                r = RTNNode(item, j)\n",
    "                \n",
    "                j -= 1 # уменьшаем j\n",
    "                t += 1 # инкрементируем t\n",
    "            \n",
    "                if last != None:\n",
    "                    r.connect(last) # связываем текущий с предыдущей итерацией\n",
    "                    \n",
    "                last = r\n",
    "                \n",
    "            start_ones.append(last)\n",
    "        \n",
    "        # печать всего RTNNode\n",
    "        print('0:')\n",
    "        # печать 0 состояния\n",
    "        for i in start_ones:\n",
    "            i.printNode()\n",
    "        # печать всех остальных\n",
    "        for i in start_ones:\n",
    "            i.printNodes()  \n",
    "                  \n",
    "        print(')')\n",
    "        print()\n",
    "        \n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "toRTN(new_map, f'{corpus_filename}_rtn.out')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
