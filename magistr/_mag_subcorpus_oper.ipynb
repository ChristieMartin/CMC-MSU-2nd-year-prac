{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание: <a class=\"anchor\" id=\"contents\"></a>\n",
    "* [Обработка корпуса](#corpus)\n",
    "* [Визуализация предложения из корпуса](#visual)\n",
    "* [Генерация и обработка грамматики](#grammar)\n",
    "* [Генерация рекурсивной сети переходов](#rtn)\n",
    "* [Генерация JSON](#json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка корпуса: <a class=\"anchor\" id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import (parse, Element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_filename = 'Glavnaya_taina_nachala_voiny'\n",
    "#corpus_filename = 'pedagogika'\n",
    "\n",
    "corpus_filename = 'sirija'\n",
    "\n",
    "file_ext = '.xml'\n",
    "#file_ext = '.tgt'\n",
    "doc = parse(corpus_filename + file_ext)\n",
    "sentences = doc.getElementsByTagName('S') # все элементы с тегом S (все предложения корпуса)\n",
    "\n",
    "orig_name = corpus_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder = corpus_filename + '_ready/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "corpus_filename =  folder + corpus_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество предложений в корпусе = 79'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Количество предложений в корпусе = {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {} # словарь всей грамматики граммема - слова\n",
    "non_projective = set()\n",
    "pj = 0\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, sent: Element):\n",
    "        self.id = sent.getAttribute('ID')\n",
    "        self.words = []\n",
    "        \n",
    "        self.parseWords(sent.getElementsByTagName('W'))\n",
    "        # получаем все элементы xml с тегом W (слова)\n",
    "        \n",
    "    def parseWords(self, rawWords):\n",
    "        \n",
    "        self.wordMap = {} # для последующего связывания слов\n",
    "        # ключ - доминатор(айди доминатора) этого слова\n",
    "        # значение - список слов, для которых доминатор равен ключу\n",
    "        \n",
    "        for rawWord in rawWords:\n",
    "            \n",
    "            word = Word(rawWord, self.id) # переносим в класс\n",
    "            \n",
    "            self.words.append(word) # добавляем в общий список слов\n",
    "            \n",
    "            if word.dom == '_root':\n",
    "                self.rootWord = word # корневое слово\n",
    "                \n",
    "            # добавление в мапу\n",
    "            if word.dom in self.wordMap.keys():\n",
    "                self.wordMap[word.dom].append(word)\n",
    "            else:\n",
    "                self.wordMap[word.dom] = [word]\n",
    "\n",
    "        # цикл по всем словам, чтобы связать их с помощью мапы\n",
    "        for word in self.words:\n",
    "            if word.id in self.wordMap.keys():\n",
    "                for d in self.wordMap[word.id]:\n",
    "                    word.addWord(d)\n",
    "    def printGram(self):\n",
    "        # печать грамматики предложения = печать грамматики одного слова(которое печатает все свои связанные слова, то есть все слова в предложении)\n",
    "        self.rootWord.printGram(True) \n",
    "        \n",
    "        \n",
    "class Word:\n",
    "    def __init__(self, w: Element, sentId):\n",
    "        self.dom = w.getAttribute('DOM')\n",
    "        self.feat = w.getAttribute('FEAT')\n",
    "        self.feat = self.feat.replace(' МЕТА', '').replace(' НАСТ ', ' ').replace(' СЛ', '').replace('COM', '')\n",
    "        \n",
    "        if self.feat == '':\n",
    "            self.feat = 'S'\n",
    "        else:\n",
    "            self.feat = self.feat.split(' ')[0]\n",
    "            \n",
    "        self.id = w.getAttribute('ID')\n",
    "        self.lemma = w.getAttribute('LEMMA')\n",
    "        self.link = w.getAttribute('LINK')\n",
    "        \n",
    "        v = \" \".join(t.nodeValue for t in w.childNodes if t.nodeType == t.TEXT_NODE).lower().strip()\n",
    "        # v - просто слово\n",
    "        \n",
    "        if len(v) != 0 and v[-1] == '.':\n",
    "            v = v[:-1]\n",
    "        if v != '':\n",
    "            # добавление слова в словарь\n",
    "            if self.feat in d.keys():\n",
    "                d[self.feat].add(v)\n",
    "            else:\n",
    "                d[self.feat] = {v}\n",
    "        self.v = v\n",
    "        \n",
    "        \n",
    "        self.sentId = sentId\n",
    "        \n",
    "        self.connectedWords = [] #связанные с этим словом слова\n",
    "        \n",
    "    def addWord(self, w):\n",
    "        # добавление слова в связанные с этим словом слова\n",
    "        self.connectedWords.append(w)\n",
    "        \n",
    "    def printGram(self, checkProj):\n",
    "        if checkProj:\n",
    "            #t = checkProjectivity(self, {}, 0)\n",
    "            global seen_ids\n",
    "            seen_ids = set()\n",
    "            t = is_non_projective(self)\n",
    "            if t:\n",
    "                #global pj\n",
    "                #pj += 1\n",
    "                \n",
    "                #print('not proj')\n",
    "                # закомментировать return, чтобы такие предложения не пропускались\n",
    "                #print(f'\\nNOT PROJECTIVE, {self.sentId}\\n')\n",
    "                non_projective.add(self.sentId)\n",
    "                return\n",
    "            print('R', end='')\n",
    "        print('D{' + f'[{self.feat}' + ']}->', end = '') # F(t) ->\n",
    "        \n",
    "        if self.connectedWords == []:\n",
    "            print(f'[{self.feat}]\\n', end = '') # когда узел - терминальный\n",
    "            \n",
    "        else:\n",
    "            t = False # для расположения граммем слова в нужном месте\n",
    "            for w in self.connectedWords:\n",
    "                \n",
    "                # проход по всем словам в связанных словах\n",
    "                if not t and (int(w.id) > int(self.id)): \n",
    "                    # когда этого не происходило ранее и когда айди текущего связанного слова превысило айди самого слова\n",
    "                    print(f'[{self.feat}]', end = '')\n",
    "                    t = True\n",
    "                     \n",
    "                print(';D{[' + f'{w.feat}' + '], ' + f'{w.link}' + '};', end = '') # D(t, s)\n",
    "            if not t:\n",
    "                print(f'[{self.feat}]', end = '')\n",
    "            for w in self.connectedWords:\n",
    "                s = 'D'\n",
    "                #if w.dom == '_root':\n",
    "                #    s = 'RF'\n",
    "                print('\\nD{[' + f'{w.feat}], {w.link}' + '}->' + s + '{[' + f'{w.feat}' + ']}') \n",
    "                # D(t, s) -> F(t)\n",
    "                #print() # раскомментировать и закомментировать предыдущую, если не хотим печатать D(t, s) -> F(t)\n",
    "                w.printGram(False)\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "def is_non_projective(w):\n",
    "    for v in [f for f in w.connectedWords if int(f.id) < int(w.id)]:\n",
    "        t = is_non_projective(v)\n",
    "        if t:\n",
    "            return True\n",
    "        \n",
    "    if any(map(lambda x: int(x) > int(w.id), seen_ids)):\n",
    "        return True\n",
    "    seen_ids.add(w.id)\n",
    "    \n",
    "    for v in [f for f in w.connectedWords if int(f.id) > int(w.id)]:\n",
    "        t = is_non_projective(v)\n",
    "        if t:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация дерева: <a class=\"anchor\" id=\"visual\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_tree:\n",
    "    import graphviz\n",
    "\n",
    "    def drawSentenceTree(sentence_id, open_pdf = False):\n",
    "        sentence = Sentence(sentences[sentence_id - 1])\n",
    "        SCALE_FACTOR = 2\n",
    "        grviz = graphviz.Digraph(f'dependency_tree_{sentence.id}', engine=\"neato\",)\n",
    "        def addWordsToTree(grviz, word, level):\n",
    "            x_position = int(word.id) * SCALE_FACTOR\n",
    "            y_position = -level * SCALE_FACTOR\n",
    "            if word.dom != '_root':\n",
    "                grviz.edge(word.dom, word.id, label=word.link)\n",
    "            grviz.node(word.id, word.id + '\\n' + word.v + '\\n' + word.feat, pos=f\"{x_position},{y_position}!\")\n",
    "            for child in word.connectedWords:\n",
    "                addWordsToTree(grviz, child, level + 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        addWordsToTree(grviz, sentence.rootWord, 0)\n",
    "        if open_pdf:\n",
    "            grviz.view()\n",
    "        return grviz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_tree:\n",
    "    grviz = drawSentenceTree(6, open_pdf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_tree:\n",
    "    grviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация и обработка грамматики: <a class=\"anchor\" id=\"grammar\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentences(sentence_id = None):\n",
    "    if sentence_id != None:\n",
    "        parseSentence(sentences[sentence_id - 1])\n",
    "    else:\n",
    "        for sent in sentences:\n",
    "            # пробегаемся по всем предложениям корпуса\n",
    "            parseSentence(sent)\n",
    "\n",
    "def parseSentence(sent: Element):\n",
    "    sentence = Sentence(sent)\n",
    "    sentence.printGram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#corpus_filename = corpus_filename + '_48'\n",
    "filename = corpus_filename + '_' + 'gram.out'\n",
    "#filename = 'test_test_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open(filename, 'w', encoding = 'utf-8')\n",
    "\n",
    "sys.stdout = f\n",
    "# перенаправление stdout в файл, чтобы все печаталось в файл\n",
    "#pj = 0\n",
    "#parseSentences(sentence_id=6)\n",
    "parseSentences()\n",
    "\n",
    "#print(pj)\n",
    "\n",
    "# перенаправление обратно\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время, потраченное на генерацию грамматики - 0.08650016784667969\n"
     ]
    }
   ],
   "source": [
    "t_after_gram = time.time()\n",
    "print(f'Время, потраченное на генерацию грамматики - {t_after_gram - t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество непроективных деревьев в sirija_ready/sirija 5'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Количество непроективных деревьев в {corpus_filename} {len(non_projective)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_sorted = corpus_filename + '_' + 'gram_sorted.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rules_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf8') as file:\n",
    "        rules = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "    return process_rules(rules)\n",
    "\n",
    "def process_rules(rules):\n",
    "    rules = rules[::-1]\n",
    "\n",
    "    replacements = {}\n",
    "    to_del = []\n",
    "\n",
    "    for i in range(len(rules)):\n",
    "\n",
    "        left, right = rules[i].split('->')\n",
    "        left = left.strip()\n",
    "        right = right.strip()\n",
    "        \n",
    "        if right in replacements:\n",
    "            if 'D{' not in replacements[right]:\n",
    "                rules[i] = f\"{left}->{replacements[right]}\"\n",
    "                to_del.append(f\"{right}->{replacements[right]}\")\n",
    "        else:\n",
    "            replacements[left] = right\n",
    "    i = 0\n",
    "    while i < len(rules):\n",
    "        rule = rules[i]\n",
    "        if rule in to_del:\n",
    "            del rules[i]\n",
    "            to_del.remove(rule)\n",
    "        else:\n",
    "            i += 1\n",
    "    return rules[::-1]\n",
    "\n",
    "def print_to_file(rules, fname_sorted):\n",
    "    with open(fname_sorted, 'w', encoding = 'utf-8') as f:\n",
    "        for line in rules:\n",
    "            if len(line) != 0 and line[-1] == ';':\n",
    "                line = line[:-1].strip()\n",
    "            line = line.replace(';;', ';')\n",
    "            line = line.replace('->;', '->')\n",
    "            print(line, file = f)\n",
    "\n",
    "def remove_duplicates(rules):\n",
    "    res = []\n",
    "    seen_rules = set()\n",
    "    for rule in rules:\n",
    "        if rule not in seen_rules:\n",
    "            res.append(rule)\n",
    "        seen_rules.add(rule)\n",
    "    return res\n",
    "        \n",
    "\n",
    "processed_rules = process_rules_from_file(filename)\n",
    "print_to_file(remove_duplicates(processed_rules), filename_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сортировка и удаление дубликатов в файле\n",
    "def printSortedNoDuplicatesFile(fname, fname_sorted):\n",
    "    lines_seen = set()\n",
    "    with open(fname, 'r', encoding = 'utf-8') as r:\n",
    "        with open(fname_sorted, 'w', encoding = 'utf-8') as f:\n",
    "            for line_orig in sorted(r):\n",
    "                if line_orig not in lines_seen:\n",
    "                    # чистим от пробелов\n",
    "                    line = str(line_orig.strip())\n",
    "\n",
    "                    if len(line) != 0 and line[-1] == ';':\n",
    "                        # удаляю лишние ;\n",
    "                        line = line[:-1].strip()\n",
    "                        \n",
    "                    line = line.replace(';;', ';')\n",
    "                    line = line.replace('->;', '->')\n",
    "                    \n",
    "                    line += '\\n'  \n",
    "                    if line == '\\n':\n",
    "                        # empty line\n",
    "                        continue\n",
    "                    \n",
    "                    print(line, end = '', file = f)\n",
    "                    \n",
    "                    lines_seen.add(line_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printSortedNoDuplicatesFile(filename, filename_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# печать словаря\n",
    "def printDictionary(d, fname):\n",
    "    with open(fname, 'w', encoding='utf-8') as f:\n",
    "        for key, value in d.items():\n",
    "            s = ' | '.join(value)\n",
    "            print(f'[{key}] = {s}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "printDictionary(d, f'{corpus_filename}_dict.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gram_map = {}\n",
    "f_gram_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToMap(mapName, key, value):\n",
    "    # добавление в словарь по ключу key value (само значение - список)\n",
    "    if key in mapName.keys():\n",
    "        mapName[key].append(value)\n",
    "    else:\n",
    "        mapName[key] = [value]\n",
    "\n",
    "def mapGrammar(filename):\n",
    "    # запись всей грамматики в словарь\n",
    "    # d_gram_map - словарь для D нетерминалов\n",
    "    # f_gram_map - словарь для F нетерминалов\n",
    "    \n",
    "    with open(filename, 'r', encoding = 'utf-8') as r:\n",
    "        for line in r:\n",
    "            s = line.split('->')\n",
    "            p = s[0].strip()\n",
    "            w = s[1].strip().replace('\\n', '')\n",
    "            if (p[0] == 'D'):\n",
    "                addToMap(d_gram_map, p, w)\n",
    "            else:\n",
    "                addToMap(f_gram_map, p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGrammarMap(mapName, filename_min):\n",
    "    # печать грамматики\n",
    "    with open(filename_min, 'w', encoding = 'utf-8') as f:\n",
    "        for key, value in mapName.items():\n",
    "            s = '|'.join(value)\n",
    "            s = ';'.join(s.split(';'))\n",
    "            print(key, '->', s, file = f, sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_d = []\n",
    "\n",
    "def setFToD():\n",
    "    # подстановка F нетерминалов в D\n",
    "    for key, value in d_gram_map.items():\n",
    "        d_gram_map[key] = f_gram_map[d_gram_map[key][0]]\n",
    "        \n",
    "def processRoot():\n",
    "    for key, value in f_gram_map.items():\n",
    "        if key[0] == 'R':\n",
    "            k = key.replace('RD', 'D')\n",
    "            if k in d_gram_map:\n",
    "                d_gram_map[k] = value + d_gram_map[k]\n",
    "            else:  \n",
    "                d_gram_map[k] = value\n",
    "            root_d.append(k)\n",
    "\n",
    "def addFToD():\n",
    "    for key, value in f_gram_map.items():\n",
    "        newKey = key.replace('RF', 'D').replace('F', 'D')\n",
    "        if newKey in d_gram_map:\n",
    "            d_gram_map[newKey] = d_gram_map[newKey] + value\n",
    "        else:\n",
    "            d_gram_map[newKey] = value\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeRecursion(d_gram_map):\n",
    "    # подставить D в D где это возможно\n",
    "    seen = []\n",
    "    t = True\n",
    "    while t: \n",
    "        t = False # закончится, если справа не останется D, или все правила просмотрены и обработаны(останутся только те, в которых есть рекурсии)\n",
    "        for key, value in d_gram_map.items():\n",
    "            if 'D{' not in str(value) and key not in seen: # если справа есть нетерминал D\n",
    "                t = True\n",
    "                seen.append(key)\n",
    "                \n",
    "                for k, v in d_gram_map.items():\n",
    "                    l = []\n",
    "                    if key in str(v):\n",
    "                        for item in v:\n",
    "                            for val in value:\n",
    "                                l.append(item.replace(key, val)) # заменяю D на D из других правил\n",
    "                    if l != []:\n",
    "                        d_gram_map[k] = l\n",
    "                        \n",
    "    return d_gram_map\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gram_map = {}\n",
    "f_gram_map = {}\n",
    "\n",
    "t_before_rsp = time.time()\n",
    "\n",
    "mapGrammar(f'{corpus_filename}_gram_sorted.out')\n",
    "#mapGrammar(f'{corpus_filename}_gram_sorted_root.out')\n",
    "\n",
    "#setFToD()\n",
    "processRoot()\n",
    "\n",
    "printGrammarMap(d_gram_map, f'{corpus_filename}_gram_min_test.out')\n",
    "\n",
    "\n",
    "#for key in f_gram_map.keys():\n",
    "#    d_gram_map[key.replace('RF', 'F')] = f_gram_map[key]\n",
    "\n",
    "new_map = d_gram_map\n",
    "#new_map = removeRecursion(copy.deepcopy(d_gram_map))\n",
    "\n",
    "printGrammarMap(new_map, f'{corpus_filename}_gram_min.out')\n",
    "printSortedNoDuplicatesFile(f'{corpus_filename}_gram_min.out', f'{corpus_filename}_gram_min_sorted.out')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация рекурсивной сети переходов: <a class=\"anchor\" id=\"rtn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = 'DESCRIPTOR'\n",
    "\n",
    "root_rtn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_term_operators_no_comma(SSR = None):\n",
    "    operators = [\n",
    "        '@CopySSR',\n",
    "        '@ToTier',\n",
    "    ]\n",
    "    return ' '.join(operators)\n",
    "\n",
    "def non_term_operators_comma(SSR):\n",
    "    operators = [\n",
    "        f'@ToSSR(\"{SSR}\")',\n",
    "        '@CopyMainWord',\n",
    "        '@CopyBonus'\n",
    "    ]\n",
    "    return ' '.join(operators)\n",
    "\n",
    "def term_operators(SSR = None):\n",
    "    operators = [\n",
    "        '@ToMainWord',\n",
    "        '' if SSR is None else f'@ToSSR(\"{SSR}\")',\n",
    "    ]\n",
    "    return ' '.join(operators)\n",
    "\n",
    "def get_ssr(term):\n",
    "    return term[term.find(', ') + 2:term.find('}')]\n",
    "\n",
    "class RTN:\n",
    "    def __init__(self, name, startingNodes = [], makeStateMap = True):\n",
    "        self.name = name\n",
    "        self.startingNodes = startingNodes\n",
    "        self.reversed = False\n",
    "        \n",
    "        if makeStateMap:\n",
    "            self.makeStateMap()\n",
    "        \n",
    "    def reverse(self):\n",
    "        self.reversed = not self.reversed\n",
    "        new_state_map = {}\n",
    "        for key, value in self.state_map.items():\n",
    "            for node in value:\n",
    "                ind = node.index if node.index else '*'\n",
    "\n",
    "                if key == '*' or str(key) == '0':\n",
    "                    node.index = None\n",
    "                    node.isEnd = True\n",
    "                else:\n",
    "                    node.index = key\n",
    "                    node.isEnd = False\n",
    "                    \n",
    "                if ind not in new_state_map:\n",
    "                    new_state_map[ind] = [node]\n",
    "                else:\n",
    "                    new_state_map[ind].append(node)\n",
    "        new_state_map[0] = new_state_map['*']\n",
    "        del new_state_map['*']\n",
    "\n",
    "        self.state_map = new_state_map  \n",
    "        \n",
    "        # state_map:\n",
    "        \"\"\"\n",
    "        {\n",
    "            'название_состояния': 'список RTNNode в этом состоянии',\n",
    "            ...\n",
    "        } \n",
    "        \n",
    "        {\n",
    "            '0': [\n",
    "                RTNNode('a', index = 1),\n",
    "                RTNNode('b', isEnd = True), \n",
    "            ],\n",
    "            '1': [\n",
    "                RTNNode('c', isEnd = True), \n",
    "            ]\n",
    "        } \n",
    "        ===\n",
    "        {'0': ['a' -> 1, 'b' -> '*'], '1': ['c' -> '*']}\n",
    "        \"\"\"\n",
    "           \n",
    "            \n",
    "    # переименнование индексов и состояний\n",
    "    def renameIndexes(self):\n",
    "        new_state_map = {}\n",
    "        index_map = {}\n",
    "        new_index = 0\n",
    "        \n",
    "        keys = sorted(self.state_map.keys())\n",
    "        keys.remove('0')\n",
    "        keys = ['0'] + keys\n",
    " \n",
    "        for k in keys:\n",
    "            if str(k) in self.state_map:\n",
    "                key = str(k)\n",
    "            else:\n",
    "                key = k\n",
    "            \n",
    "            new_key = str(new_index)\n",
    "            \n",
    "            \n",
    "            new_state_map[new_key] = self.state_map[key]\n",
    "            if '*' in key:\n",
    "                new_state_map[new_key].append(RTNNode('<>', isEnd = True))\n",
    "            index_map[key] = new_key\n",
    "            del self.state_map[key]\n",
    "            new_index += 1\n",
    "        \n",
    "        for value in new_state_map.values():\n",
    "            for node in value:\n",
    "                if node.index:\n",
    "                    node.index = index_map[str(node.index)]\n",
    "        check_zero_state = True\n",
    "        to_state = -1\n",
    "        \n",
    "        for item in new_state_map['0']:\n",
    "            if not item.empty:\n",
    "                check_zero_state = False\n",
    "                break\n",
    "            if to_state == -1:\n",
    "                to_state = item.index\n",
    "            elif to_state != item.index:\n",
    "                check_zero_state = False\n",
    "                break\n",
    "            \n",
    "        if check_zero_state:\n",
    "            new_zero = new_state_map['0'][0].index\n",
    "            new_state_map['0'] = new_state_map[str(new_zero)]\n",
    "            del new_state_map[str(new_zero)]\n",
    "        else:\n",
    "            toRemove = []\n",
    "            for item in new_state_map['0']:\n",
    "                if item.empty:\n",
    "                    toRemove.append(item)\n",
    "            if len(toRemove) != len(new_state_map['0']): \n",
    "                for item in toRemove:\n",
    "                    new_state_map['0'].remove(item)\n",
    "           \n",
    "        \n",
    "            \n",
    "        self.state_map = new_state_map\n",
    "        \n",
    "    # в случае когда РСП строилась связыванием RTNNode друг с другом\n",
    "    def makeStateMap(self):\n",
    "        state_map = {}  \n",
    "        \n",
    "        def add_to_map(node, state_index):\n",
    "            if state_index not in state_map:   \n",
    "                state_map[state_index] = [node]\n",
    "            else:\n",
    "                state_map[state_index].append(node)\n",
    "            \n",
    "            for child in node.connected:\n",
    "                add_to_map(child, node.index)\n",
    "        \n",
    "        for child in self.startingNodes:\n",
    "            add_to_map(child, 0)\n",
    "\n",
    "        self.state_map = state_map\n",
    "    \n",
    "    # отсоединить все RTNNode друг от друга(теперь используется только state_map)\n",
    "    def disconnectAll(self):\n",
    "        def disconnectNodes(node):\n",
    "            for child in node.connected:\n",
    "                disconnectNodes(child)\n",
    "            node.disconnect()\n",
    "        \n",
    "        for child in self.startingNodes:\n",
    "            disconnectNodes(child)\n",
    "        \n",
    "    def print(self):\n",
    "        print(f'${self.name} {descriptor}')\n",
    "        print('(')\n",
    "        \n",
    "        parent_ssr = None if ',' not in self.name else get_ssr(self.name)\n",
    "        \n",
    "        for key in self.state_map.keys():\n",
    "            print(f'{key}:')\n",
    "            for node in self.state_map[key]:\n",
    "                node.printNode(parent_ssr)\n",
    "                 \n",
    "        desc_operator = '@CheckSSRAnyWord' if ',' in self.name else '@CheckTier'\n",
    "        print(f') DESCRIPTOR {desc_operator}')\n",
    "\n",
    "        print()\n",
    "        \n",
    "class RTNNode:\n",
    "    # класс для рекурсивной сети переходов\n",
    "    # s - символ перехода\n",
    "    # index - в какое состояние переходим по этому нетерминалу/терминалу(цифра после)\n",
    "    # isEnd - последнее ли правило в альтернативе\n",
    "    # connected - с каким RTNNode связано текущее\n",
    "    def __init__(self, s, isEnd = False, index = None):\n",
    "        self.s = s\n",
    "        self.isEnd = isEnd\n",
    "        self.connected = []\n",
    "        self.index = index\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str((self.s, self.connected))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.s} -> {self.index if self.index else \"*\"}'\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, RTNNode):\n",
    "            return NotImplemented\n",
    "        return (self.s, self.isEnd, self.index) == (other.s, other.isEnd, other.index)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.s, self.isEnd, self.index))\n",
    "    \n",
    "    @property\n",
    "    def empty(self):\n",
    "        return self.s == '<>'\n",
    "    \n",
    "    def change_index(self, ind):\n",
    "        self.index = ind  \n",
    "        \n",
    "    def connect(self, node):\n",
    "        self.connected.append(node)\n",
    "        \n",
    "    def disconnect(self):\n",
    "        self.connected = []\n",
    "        \n",
    "    # печать одного RTNNode\n",
    "    def printNode(self, parent_ssr = None):\n",
    "        f = self.s[0] == 'D' or self.s[0] == 'F'\n",
    "        s = f'${self.s}' if f else self.s\n",
    "        \n",
    "        state = '*' if self.isEnd else self.index\n",
    "        end = (non_term_operators_no_comma() if parent_ssr == None else non_term_operators_comma(parent_ssr)) if f else term_operators() if parent_ssr == None else term_operators(parent_ssr)\n",
    "        end = end.strip()\n",
    "        \n",
    "        if s == '<>':\n",
    "            end = ''\n",
    "            \n",
    "        end_string =  f'{state} {end}'\n",
    "        end_string = end_string.strip()\n",
    "        \n",
    "        print(s, end = f' {end_string}; \\n')\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# все цепочки для РСП\n",
    "# не работает, если есть петли\n",
    "def rtn_chain(rtn):\n",
    "    def build_chain(state_map, cur_state, cur_chain):\n",
    "        s = set()\n",
    "        if str(cur_state) in state_map:\n",
    "            state = state_map[str(cur_state)]\n",
    "        elif int(cur_state) in state_map:\n",
    "            state = state_map[int(cur_state)]\n",
    "        else:\n",
    "            state = []\n",
    "            \n",
    "        for node in state:\n",
    "            if node.isEnd:\n",
    "                if node.s == '<>':\n",
    "                    s.add(cur_chain)\n",
    "                else:\n",
    "                    s.add(cur_chain + node.s)\n",
    "            else:\n",
    "                s.update(build_chain(state_map, node.index, cur_chain + node.s if node.s != '<>' else ''))\n",
    "        return s\n",
    "    return build_chain(rtn.state_map, 0 if 0 in rtn.state_map else '0', '')\n",
    "\n",
    "\n",
    "# словарь всех переходов для каждого из состояний\n",
    "# {0: {'a': [1,2], 'd': [3]}, 1: ['c': ['*']]}\n",
    "# из 0 по 'a' в 1,2, по 'd' в 3 и тд \n",
    "def rtn_transition_map(rtn):\n",
    "    transition_map = {}  \n",
    "    \n",
    "    def add_to_map(node, state_index):\n",
    "        if state_index not in transition_map:   \n",
    "            transition_map[state_index] = {}\n",
    "        index = node.index if node.index else '*'\n",
    "        \n",
    "        if node.s in transition_map[state_index]:\n",
    "            transition_map[state_index][node.s].append(index)\n",
    "        else:\n",
    "            transition_map[state_index][node.s] = [index]\n",
    "    \n",
    "    for key, value in rtn.state_map.items():\n",
    "        for node in value:\n",
    "            add_to_map(node, key)\n",
    "\n",
    "    return transition_map\n",
    "\n",
    "# детерминизация\n",
    "# перевод РСП в словарь переходов\n",
    "# детерминизация словаря переходов\n",
    "# перевод детерминизированного словаря обратно в рсп\n",
    "def determinize(rtn):\n",
    "    transition_map = rtn_transition_map(rtn)\n",
    "\n",
    "    determinized_transitions = determinize_nfa(transition_map)\n",
    "    \n",
    "    new_rtn = state_map_to_rtn(determinized_transitions, rtn.name, rtn.reversed)\n",
    "    \n",
    "    return new_rtn\n",
    "\n",
    "def determinize_nfa(nfa):\n",
    "    symbols = set()\n",
    "    for transitions in nfa.values():\n",
    "        symbols.update(transitions.keys())\n",
    "    \n",
    "    def dfa_transitions_string(states, nfa):\n",
    "        transitions = {}\n",
    "        for symbol in symbols:\n",
    "            reachable = set()\n",
    "            for state in states.split('_'):\n",
    "                if state != '*' and state in nfa and symbol in nfa[state]:\n",
    "                    reachable.update(nfa[state][symbol])\n",
    "                elif state != '*' and int(state) in nfa and symbol in nfa[int(state)]:\n",
    "                    reachable.update(nfa[int(state)][symbol])\n",
    "            try:\n",
    "                if states != '*' and states in nfa and symbol in nfa[states]:\n",
    "                    reachable.update(nfa[states][symbol])\n",
    "                elif states != '*' and int(states) in nfa and symbol in nfa[int(states)]:\n",
    "                    reachable.update(nfa[int(states)][symbol])\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            reachable_str = '_'.join(sorted(map(str, reachable)))\n",
    "            \n",
    "            if reachable_str:\n",
    "                transitions[symbol] = reachable_str\n",
    "        return transitions\n",
    "\n",
    "    dfa = {}\n",
    "\n",
    "    stack = ['0', '*']\n",
    "    \n",
    "    while stack:\n",
    "        state = stack.pop()\n",
    "        transitions = dfa_transitions_string(state, nfa)\n",
    "\n",
    "        dfa[state] = transitions\n",
    "\n",
    "        for next_state in transitions.values():\n",
    "            if next_state not in dfa:\n",
    "                stack.append(next_state)\n",
    "    \n",
    "    dfa = {k: v for k, v in dfa.items() if v}    \n",
    "    return dfa\n",
    "\n",
    "\n",
    "# перевод словаря переходов обратно в рсп\n",
    "def state_map_to_rtn(dfa, name, reversed):\n",
    "    new_state_map = {}\n",
    "\n",
    "    for key, value in dfa.items():\n",
    "        for node in value:\n",
    "            rtnnode = RTNNode(node, isEnd = dfa[key][node] == '*')\n",
    "\n",
    "            if dfa[key][node] == '0' or dfa[key][node] == '*':\n",
    "                rtnnode.index = None\n",
    "                rtnnode.isEnd = True\n",
    "            else:\n",
    "                rtnnode.index = dfa[key][node]\n",
    "                rtnnode.isEnd = False\n",
    "                \n",
    "            if key not in new_state_map:\n",
    "                new_state_map[key] = [rtnnode]\n",
    "            else:\n",
    "                new_state_map[key].append(rtnnode)\n",
    "                \n",
    "    rtn = RTN(name)\n",
    "    rtn.state_map = new_state_map\n",
    "\n",
    "    rtn.reversed = reversed\n",
    "    \n",
    "    return rtn\n",
    "\n",
    "# минимизация\n",
    "# реверс -> детерминизация -> переименнование индексов и состояний -> реверс -> детерминизация -> переименнование индексов и состояний\n",
    "def minimize(rtn):\n",
    "    new_rtn = rtn\n",
    "    new_rtn.reverse()\n",
    "    new_rtn = determinize(new_rtn)\n",
    "    new_rtn.renameIndexes()\n",
    "    new_rtn.reverse()\n",
    "    new_rtn = determinize(new_rtn)\n",
    "    new_rtn.disconnectAll()\n",
    "    new_rtn.renameIndexes()\n",
    "    return new_rtn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация РСП\n",
    "# использование: visualize_state_machine(rtn.state_map)\n",
    "# pdf файл открывается автоматически!\n",
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_state_machine(state_map):\n",
    "    dot = Digraph(comment='State Machine')\n",
    "\n",
    "    for state, nodes in state_map.items():\n",
    "        dot.node(str(state), str(state))\n",
    "        for node in nodes:\n",
    "            end_state = '*' if node.isEnd else node.index\n",
    "            print(node.s)\n",
    "            dot.edge(str(state), str(end_state), label = node.s if node.s != '<>' else 'eps')\n",
    "\n",
    "    dot.render('state_machine.gv', view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_rtn = True # минимизировать ли РСП\n",
    "\n",
    "count_all_states = 0 # подсчет общего числа состояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def toRTN(new_map, fname):\n",
    "    orig_stdout = sys.stdout\n",
    "    f = open(fname, 'w', encoding = 'utf-8')\n",
    "    sys.stdout = f\n",
    "    \n",
    "    global count_all_states\n",
    "    \n",
    "    for key in new_map.keys():\n",
    "        l = new_map[key] # ['a;D1', 'D2;D1']\n",
    "        new_l = [] # [['a', 'D1'], ['D2', 'D1']]\n",
    "        for item in l:\n",
    "            p = item.split(';')\n",
    "            new_l.append(p)\n",
    "            \n",
    "        \n",
    "        \n",
    "        start_ones = []\n",
    "        \n",
    "        for items in new_l:\n",
    "            \n",
    "            last = None # RTNNode на предыдущей итерации\n",
    "            \n",
    "            \n",
    "            for i, item in enumerate(reversed(items)):\n",
    "                # цикл по всем терминалам и нетерминалам в альтернативе в обратном порядке\n",
    "                r = RTNNode(item, isEnd = i == 0)\n",
    "                \n",
    "                if last != None:\n",
    "                    r.connect(last) # связываем текущий с предыдущей итерацией\n",
    "                    \n",
    "                last = r\n",
    "                \n",
    "            start_ones.append(last)\n",
    "        \n",
    "        l = 1\n",
    "        for r_node in start_ones:\n",
    "            r_tmp = r_node\n",
    "            while not r_tmp.isEnd:\n",
    "                r_tmp.change_index(l)\n",
    "                l += 1\n",
    "                r_tmp = r_tmp.connected[0]\n",
    "        \n",
    "        rtn_network = RTN(key, start_ones)\n",
    "        \n",
    "        \n",
    "        if key in root_d:\n",
    "            root_rtn.append(rtn_network)\n",
    "            \n",
    "        if minimize_rtn:\n",
    "            chain1 = rtn_chain(rtn_network)\n",
    "            \n",
    "            rtn_network = minimize(rtn_network)\n",
    "            \n",
    "            chain2 = rtn_chain(rtn_network)\n",
    "            #if len(chain2.symmetric_difference(chain1)) != 0:\n",
    "                # если цепочки не совпадает, что-то пошло не так при минимизации\n",
    "            #    print('!!!')\n",
    "            \n",
    "        rtn_network.print()\n",
    "        \n",
    "        count_all_states += len(rtn_network.state_map)\n",
    "        \n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_descriptor():\n",
    "    return 'DECLARE DESCRIPTOR (MAINWORD TIER() SSR{\"\"} BONUS{0})\\n\\n'\n",
    "\n",
    "def root_operators():\n",
    "    operators = [\n",
    "        '@CopySSR',\n",
    "        '@CopyMainWord',\n",
    "        '@CopyBonus'\n",
    "    ]\n",
    "    return ' '.join(operators)\n",
    "\n",
    "def add_root_to_file(root_d, filename):\n",
    "    with open(filename, 'r', encoding='utf8') as contents:\n",
    "      save = contents.read()\n",
    "    with open(filename, 'w', encoding='utf8') as contents:\n",
    "        contents.write(root_descriptor())\n",
    "        contents.write('$D{' + orig_name + '}\\n')\n",
    "        contents.write('(\\n')\n",
    "        contents.write('0:\\n')\n",
    "        for root in root_d:\n",
    "            contents.write('$' + root + f' * {root_operators()};\\n')\n",
    "        contents.write(') DESCRIPTOR\\n\\n')\n",
    "    with open(filename, 'a', encoding='utf8') as contents:\n",
    "        contents.write(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "toRTN(new_map, f'{corpus_filename}_rtn.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество состояний в рекурсивной сети переходов = 85'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Количество состояний в рекурсивной сети переходов = {len(new_map)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Общее количество состояний в рекурсивной сети переходов = 247'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Общее количество состояний в рекурсивной сети переходов = {count_all_states}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_root_to_file(root_d, f'{corpus_filename}_rtn.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время, потраченное на генерацию РСП - 0.1659984588623047'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Время, потраченное на генерацию РСП - {time.time() - t_before_rsp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разные тесты на минимизацию\n",
    "\n",
    "test_minimize = False\n",
    "test_minimize_2 = False\n",
    "test_minimize_3 = False\n",
    "test_minimize_4 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': [a -> 1, a -> 2], '1': [a -> 3], '2': [a -> 2, b -> 4, b -> *], '3': [a -> 2, a -> 5], '4': [b -> 4, b -> 5, b -> *], '5': [b -> 6], '6': [b -> *]}\n",
      "{'0': [a -> 3], '1': [b -> 1, <> -> *], '3': [b -> 1, a -> 3]}\n",
      "a\n",
      "b\n",
      "<>\n",
      "b\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "if test_minimize:\n",
    "    name = \"exampleNFA\"\n",
    "    s1 = RTNNode(\"a\")\n",
    "    s2 = RTNNode(\"a\")\n",
    "    s3 = RTNNode(\"b\", isEnd = True)\n",
    "    s4 = RTNNode(\"c\", isEnd = True)\n",
    "    s7 = RTNNode(\"f\", isEnd = True)\n",
    "    s5 = RTNNode(\"d\")\n",
    "    s6 = RTNNode(\"e\", isEnd = True)\n",
    "\n",
    "    s1.index = 1\n",
    "    s2.index = 2\n",
    "    s5.index = 3\n",
    "    s1.connect(s4)\n",
    "    s1.connect(s7)\n",
    "    s2.connect(s3)\n",
    "    s5.connect(s6)\n",
    "\n",
    "    rtn = RTN(name, [s1, s2, s5])\n",
    "    chain1 = rtn_chain(rtn)\n",
    "    print(chain1)\n",
    "    \n",
    "    new_rtn = minimize(rtn)\n",
    "    print(new_rtn.state_map)\n",
    "    chain = rtn_chain(new_rtn)\n",
    "    print(chain)\n",
    "    \n",
    "    print(chain == rtn_chain(rtn))\n",
    "    \n",
    "    print(len(chain.symmetric_difference(chain1)))\n",
    "\n",
    "if test_minimize_2:\n",
    "    name = \"$D{[PART]}\"\n",
    "    s1 = RTNNode(\"a\")\n",
    "    s2 = RTNNode(\"b\")\n",
    "    s3 = RTNNode(\"c\")\n",
    "    s4 = RTNNode(\"c\", isEnd=True)\n",
    "    s5 = RTNNode(\"c\", isEnd=True)\n",
    "    s6 = RTNNode(\"b\", isEnd=True)\n",
    "    \n",
    "    s1.index = 1\n",
    "    s2.index = 2\n",
    "    s3.index = 3\n",
    "    \n",
    "    s1.connect(s4)\n",
    "    s2.connect(s5)\n",
    "    s3.connect(s6)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rtn = RTN(name, [s1, s2, s3])\n",
    "    chain1 = rtn_chain(rtn)\n",
    "    print(chain1)\n",
    "    \n",
    "    new_rtn = minimize(rtn)\n",
    "    print(new_rtn.state_map)\n",
    "    chain = rtn_chain(new_rtn)\n",
    "    print(chain)\n",
    "    \n",
    "    print(chain == rtn_chain(rtn))\n",
    "    \n",
    "    print(len(chain.symmetric_difference(chain1)))\n",
    "\n",
    "if test_minimize_3:\n",
    "    name = \"$D\"\n",
    "    s1 = RTNNode(\"a\")\n",
    "    s1.index = 1\n",
    "    s2 = RTNNode(\"b\")\n",
    "    s2.index = 3\n",
    "    s3 = RTNNode(\"b\")\n",
    "    s3.index = 5\n",
    "    s4 = RTNNode(\"c\")\n",
    "    s4.index = 8\n",
    "    s5 = RTNNode(\"c\")\n",
    "    s5.index = 9\n",
    "    s6 = RTNNode(\"c\")\n",
    "    s6.index = 10\n",
    "    s7 = RTNNode(\"c\")\n",
    "    s7.index = 12\n",
    "    s8 = RTNNode(\"d\")\n",
    "    s8.index = 14\n",
    "    s9 = RTNNode(\"c\")\n",
    "    s9.index = 16\n",
    "    s10 = RTNNode(\"c\")\n",
    "    s10.index = 18\n",
    "    \n",
    "    s11 = RTNNode(\"c\")\n",
    "    s11.index = 2\n",
    "    \n",
    "    s12 = RTNNode(\"e\")\n",
    "    s12.isEnd = True\n",
    "    \n",
    "    s13 = RTNNode(\"c\")\n",
    "    s13.index = 4\n",
    "    \n",
    "    s14 = RTNNode(\"e\")\n",
    "    s14.isEnd = True\n",
    "    \n",
    "    s15 = RTNNode(\"c\")\n",
    "    s15.index = 6\n",
    "    \n",
    "    s16 = RTNNode(\"e\")\n",
    "    s16.index = 7\n",
    "    \n",
    "    s17 = RTNNode(\"a\")\n",
    "    s17.isEnd = True\n",
    "    \n",
    "    s18 = RTNNode(\"e\")\n",
    "    s18.isEnd = True\n",
    "    \n",
    "    s19 = RTNNode(\"f\")\n",
    "    s19.isEnd = True\n",
    "    \n",
    "    s20 = RTNNode(\"e\")\n",
    "    s20.index = 11\n",
    "    \n",
    "    s21 = RTNNode(\"a\")\n",
    "    s21.isEnd = True\n",
    "    \n",
    "    s22 = RTNNode(\"f\")\n",
    "    s22.index = 13\n",
    "    \n",
    "    s23 = RTNNode(\"g\")\n",
    "    s23.isEnd = True\n",
    "    \n",
    "    s24 = RTNNode(\"c\")\n",
    "    s24.index = 15\n",
    "    \n",
    "    s25 = RTNNode(\"e\")\n",
    "    s25.isEnd = True\n",
    "    \n",
    "    s26 = RTNNode(\"e\")\n",
    "    s26.index = 17\n",
    "    \n",
    "    s27 = RTNNode(\"h\")\n",
    "    s27.isEnd = True\n",
    "    \n",
    "    s28 = RTNNode(\"i\")\n",
    "    s28.isEnd = True\n",
    "    \n",
    "    state_m = {\n",
    "        '0': [\n",
    "            s1, s2, s3, s4, s5, s6, s7, s8, s9, s10\n",
    "        ],\n",
    "        '1': [s11],\n",
    "        '2': [s12],\n",
    "        '3': [s13],\n",
    "        '4': [s14],\n",
    "        '5': [s15],\n",
    "        '6': [s16],\n",
    "        '7': [s17],\n",
    "        '8': [s18],\n",
    "        '9': [s19],\n",
    "        '10': [s20],\n",
    "        '11': [s21],\n",
    "        '12': [s22],\n",
    "        '13': [s23],\n",
    "        '14': [s24],\n",
    "        '15': [s25],\n",
    "        '16': [s26],\n",
    "        '17': [s27], \n",
    "        '18': [s28],\n",
    "    }\n",
    "    \n",
    "    rtn = RTN(name)\n",
    "    rtn.state_map = state_m\n",
    "    #chain1 = rtn_chain(rtn)\n",
    "    #print(rtn.state_map)\n",
    "    #print(chain1)\n",
    "    #visualize_state_machine(rtn.state_map)\n",
    "    \n",
    "    new_rtn = minimize(rtn)\n",
    "    print(new_rtn.state_map)\n",
    "    visualize_state_machine(new_rtn.state_map)\n",
    "    #chain = rtn_chain(new_rtn)\n",
    "    #print(chain)\n",
    "    \n",
    "    #print(chain == rtn_chain(rtn))\n",
    "    \n",
    "    #print(chain.symmetric_difference(chain1))\n",
    "    #print(len(chain.symmetric_difference(chain1)))\n",
    "    \n",
    "    \n",
    "if test_minimize_4:\n",
    "    name = 'test'\n",
    "    # 0 - H\n",
    "    # 1 - A\n",
    "    # 2 - B\n",
    "    # 3 - C\n",
    "    # 4 - D\n",
    "    # 5 - E\n",
    "    # 6 - F\n",
    "    \n",
    "    st_map = {\n",
    "        '0': [\n",
    "            RTNNode('a', index = 1),\n",
    "            RTNNode('a', index = 2), \n",
    "        ],\n",
    "        '1': [\n",
    "            RTNNode('a', index = 3),\n",
    "        ],\n",
    "        '2': [\n",
    "            RTNNode('a', index = 2),\n",
    "            RTNNode('b', index = 4),\n",
    "            RTNNode('b', isEnd = True),\n",
    "        ],\n",
    "        '3': [\n",
    "            RTNNode('a', index = 2),\n",
    "            RTNNode('a', index = 5),\n",
    "        ],\n",
    "        '4': [\n",
    "            RTNNode('b', index = 4),\n",
    "            RTNNode('b', index = 5),\n",
    "            RTNNode('b', isEnd = True),\n",
    "        ],\n",
    "        '5': [\n",
    "            RTNNode('b', index = 6),\n",
    "        ],\n",
    "        '6': [\n",
    "            RTNNode('b', isEnd = True),\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    rtn = RTN(name)\n",
    "    rtn.state_map = st_map\n",
    "    print(rtn.state_map)\n",
    "    #visualize_state_machine(rtn.state_map)\n",
    "    new_rtn = minimize(rtn)\n",
    "    print(new_rtn.state_map)\n",
    "    \n",
    "    #rtn = RTN(name)\n",
    "    #rtn.state_map = {\n",
    "    #    '0': [\n",
    "    #        RTNNode('<>', index = 1),\n",
    "    #        RTNNode('<>', index = 1),\n",
    "    #        RTNNode('<>', index = 2)\n",
    "    #    ],\n",
    "    #    '1': [\n",
    "    #        RTNNode('a', isEnd = True)\n",
    "    #    ],\n",
    "    #    '2': [\n",
    "    #        RTNNode('b', isEnd = True)\n",
    "    #    ]\n",
    "    #}\n",
    "    #rtn.renameIndexes()\n",
    "    #print(rtn.state_map)\n",
    "    \n",
    "    visualize_state_machine(new_rtn.state_map)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация JSON <a class=\"anchor\" id=\"json\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymorphy2\n",
    "from tqdm import tqdm\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "with open('pym_to_synt/pymorphy_to_syntagrus.json', 'r', encoding='utf-8') as f:\n",
    "    pts_m = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_syntagrus(word):\n",
    "    m = morph.parse(word)\n",
    "\n",
    "    l = []\n",
    "    for p in m:\n",
    "        t = set(p.tag.grammemes)\n",
    "        l.append(t)\n",
    "        \n",
    "    res = []\n",
    "    for item in l:\n",
    "        res_item = []\n",
    "        for tag in item:\n",
    "            if tag in pts_m:\n",
    "                res_item += pts_m[tag]\n",
    "        res.append(list(set(res_item)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_map():\n",
    "\n",
    "    l = []\n",
    "    exclude = ['МЕТА', 'НАСТ', 'СЛ', 'COM']\n",
    "    for s in sentences:\n",
    "        sent = Sentence(s)\n",
    "        if sent.id in non_projective:\n",
    "            continue\n",
    "        words = sent.words\n",
    "        \n",
    "        w_l = []\n",
    "        s_l = []\n",
    "        for w in words:\n",
    "            grammems = [w.feat.split(' ')]\n",
    "            for item in exclude:\n",
    "                if item in grammems[0]:\n",
    "                    grammems[0].remove(item)\n",
    "            if len(grammems[0]) == 0:\n",
    "                grammems[0].append('S')\n",
    "            v = w.v\n",
    "            \n",
    "            s_l.append(v)\n",
    "            \n",
    "            w_m = {\n",
    "                \"word\": v,\n",
    "                \"FEAT\": grammems\n",
    "            }\n",
    "            w_l.append(w_m)\n",
    "        s_m = {\n",
    "            \"sentence\": ' '.join(s_l),\n",
    "            \"words\": w_l\n",
    "        }\n",
    "        l.append(s_m)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = json_map()\n",
    "\n",
    "with open(f'{corpus_filename}_input.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(l, f, ensure_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество ключей в json разметке - 74'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Количество ключей в json разметке - {len(l)}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [В начало](#contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "82d4c6f819cf47785f735f902f00da8643513d08dab4f4c7470bccf934b8d2d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
